{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Facial Feature Extraction.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zM0uD3fYnlkM"
      },
      "outputs": [],
      "source": [
        "# Installing the Deepface framework\n",
        "\n",
        "!pip install deepface"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing Libraries\n",
        "\n",
        "import numpy as np\n",
        "import dlib\n",
        "import cv2\n",
        "from PIL import Image\n",
        "from deepface import DeepFace"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C8d-CDQInxL0",
        "outputId": "85184120-8d99-4f91-8de4-38951d604b0d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Directory  /root /.deepface created\n",
            "Directory  /root /.deepface/weights created\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "img_path = \"/content/drive/MyDrive/Metaverse ML/Images/sd.png\"\n",
        "\n",
        "# Reading the image and converting it into an numpy array\n",
        "\n",
        "img = dlib.load_rgb_image(img_path) \n",
        "\n",
        "# Gender and Race Detection\n",
        "\n",
        "res = DeepFace.analyze(img, actions = ['gender','race'])\n",
        "\n",
        "print(f\"{res['gender']}\")\n",
        "print(f\"{res['dominant_race']}\")\n",
        "\n",
        "# Glasses Detection\n",
        "\n",
        "detector = dlib.get_frontal_face_detector()  \n",
        "predictor = dlib.shape_predictor(r\"/content/drive/MyDrive/Metaverse ML/Dependencies/shape_predictor_68_face_landmarks.dat\")     # pre-trained model for 68 face landmark prediction\n",
        "\n",
        "rect = detector(img)[0]\n",
        "sp = predictor(img, rect)\n",
        "landmarks = np.array([[p.x, p.y] for p in sp.parts()])\n",
        "\n",
        "nose_bridge_x = []\n",
        "nose_bridge_y = []\n",
        "for i in [28,29,30,31,33,34,35]:\n",
        "        nose_bridge_x.append(landmarks[i][0])\n",
        "        nose_bridge_y.append(landmarks[i][1])\n",
        "        \n",
        "x_min = min(nose_bridge_x)\n",
        "x_max = max(nose_bridge_x)\n",
        "\n",
        "y_min = landmarks[20][1]\n",
        "y_max = landmarks[31][1]\n",
        "img2 = Image.open(img_path)\n",
        "img2 = img2.crop((x_min,y_min,x_max,y_max))\n",
        "\n",
        "img_blur = cv2.GaussianBlur(np.array(img2),(3,3), sigmaX=0, sigmaY=0)\n",
        "edges = cv2.Canny(image =img_blur, threshold1=85, threshold2=120)\n",
        "\n",
        "edges_center = edges.T[(int(len(edges.T)/2))]\n",
        "\n",
        "if 255 in edges_center:\n",
        " print('Glasses are present')\n",
        "else:\n",
        " print('Glasses are absent')\n",
        "\n",
        "\n",
        "# Beard Detection\n",
        "\n",
        "face_cascade = cv2.CascadeClassifier(r\"/content/drive/MyDrive/Metaverse ML/Dependencies/haarcascade_frontalface_default.xml\")      # Pre-trained model for face detection\n",
        "\n",
        "gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
        "faces = face_cascade.detectMultiScale(gray,1.1,5)\n",
        "\n",
        "for (x,y,w,h) in faces:\n",
        "  mask = np.zeros_like(img)\n",
        "  mask = cv2.ellipse(mask, (int((x+w)/1.2), y+h),(69,69), 0, 0, -180, (255,255,255),thickness=-1)\n",
        "  mask = cv2.cvtColor(mask, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "  result = np.bitwise_and(img, mask)\n",
        "  hsv_img = cv2.cvtColor(result, cv2.COLOR_BGR2HSV)\n",
        "  low_black = np.array([94, 80, 2])\n",
        "  high_black = np.array([126, 255, 255])\n",
        "  MASK = cv2.inRange(hsv_img, low_black, high_black)\n",
        "\n",
        "  if cv2.countNonZero(MASK) == 0:\n",
        "    print(\"Beard Not Found\")\n",
        "  else:\n",
        "    print(\"Beard Found\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3UJ9iEFlpiM5",
        "outputId": "ce3e8c0d-701b-4c1e-ca0d-9c87e75cd513"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Action: race: 100%|██████████| 2/2 [00:00<00:00,  3.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Man\n",
            "latino hispanic\n",
            "Glasses are absent\n",
            "Beard Found\n",
            "CPU times: user 3.2 s, sys: 171 ms, total: 3.37 s\n",
            "Wall time: 4.01 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DeepFace Framework Demo**"
      ],
      "metadata": {
        "id": "zfWz5RvJpK_o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "img_path =\"/content/drive/MyDrive/Images/sd.png\"\n",
        "\n",
        "img = cv2.imread(img_path)\n",
        "res=DeepFace.analyze(img, actions = ['race','gender'])\n",
        "print(f\"{res['dominant_race']}\")\n",
        "print(f\"{res['gender']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wLlIPWTmpQOz",
        "outputId": "48acd773-80af-4e60-e35d-d6f74fdb3c19"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Action: gender: 100%|██████████| 2/2 [00:00<00:00,  3.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "indian\n",
            "Man\n",
            "CPU times: user 833 ms, sys: 8.36 ms, total: 842 ms\n",
            "Wall time: 580 ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}